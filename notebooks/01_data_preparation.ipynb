{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Sales Prediction - Data Preparation\n",
    "\n",
    "This notebook handles:\n",
    "1. Loading raw data from Excel\n",
    "2. Data cleaning and preprocessing\n",
    "3. Feature engineering\n",
    "4. Converting to ML-ready format\n",
    "5. Saving processed data for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path('../notebooks/data')\n",
    "RAW_DATA_PATH = DATA_DIR / 'loan_sales.xlsx'\n",
    "PROCESSED_DATA_PATH = DATA_DIR / 'ml_ready_data.csv'\n",
    "DASHBOARD_DATA_PATH = Path('../analytics-dashboard/public/data/ml_ready_data.csv')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DASHBOARD_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Data directory: {DATA_DIR.absolute()}\")\n",
    "print(f\"üìÇ Dashboard directory: {DASHBOARD_DATA_PATH.parent.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "if not RAW_DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Data file not found: {RAW_DATA_PATH}\")\n",
    "\n",
    "df_raw = pd.read_excel(RAW_DATA_PATH)\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully\")\n",
    "print(f\"üìä Shape: {df_raw.shape}\")\n",
    "print(f\"\\nüìã First few rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(f\"  Rows: {df_raw.shape[0]}\")\n",
    "print(f\"  Columns: {df_raw.shape[1]}\")\n",
    "print(f\"\\nüìã Column Names:\")\n",
    "for i, col in enumerate(df_raw.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"üìä Data Types:\")\n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values:\")\n",
    "missing = df_raw.isnull().sum()\n",
    "missing_pct = (missing / len(df_raw)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"üìä Summary Statistics:\")\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parse Quarter Information\n",
    "\n",
    "Convert quarter format from Roman numerals (e.g., \"2020 I\") to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Parse R√ºbl…ôr column to extract Year and Quarter\n",
    "roman_to_int = {'I': 1, 'II': 2, 'III': 3, 'IV': 4}\n",
    "\n",
    "def parse_quarter(quarter_str):\n",
    "    \"\"\"Parse quarter string like '2020 I' to year and quarter number\"\"\"\n",
    "    if pd.isna(quarter_str):\n",
    "        return None, None\n",
    "    \n",
    "    parts = str(quarter_str).strip().split()\n",
    "    if len(parts) != 2:\n",
    "        return None, None\n",
    "    \n",
    "    year = int(parts[0])\n",
    "    quarter_roman = parts[1].strip()\n",
    "    quarter = roman_to_int.get(quarter_roman)\n",
    "    \n",
    "    return year, quarter\n",
    "\n",
    "# Apply parsing\n",
    "df[['Year', 'Quarter']] = df['R√ºbl…ôr'].apply(\n",
    "    lambda x: pd.Series(parse_quarter(x))\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Quarter parsing completed\")\n",
    "print(f\"\\nüìÖ Date Range:\")\n",
    "print(f\"  First Quarter: {df['Year'].min()}-Q{df['Quarter'].min()}\")\n",
    "print(f\"  Last Quarter: {df['Year'].max()}-Q{df['Quarter'].max()}\")\n",
    "print(f\"\\nüìã Sample of parsed data:\")\n",
    "df[['R√ºbl…ôr', 'Year', 'Quarter']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df['Time_Index'] = range(len(df))\n",
    "df['Quarter_Sin'] = np.sin(2 * np.pi * df['Quarter'] / 4)\n",
    "df['Quarter_Cos'] = np.cos(2 * np.pi * df['Quarter'] / 4)\n",
    "\n",
    "print(\"‚úÖ Time-based features created\")\n",
    "print(\"\\nüìä New Features:\")\n",
    "print(\"  - Time_Index: Sequential time index\")\n",
    "print(\"  - Quarter_Sin: Sine encoding of quarter (captures seasonality)\")\n",
    "print(\"  - Quarter_Cos: Cosine encoding of quarter (captures seasonality)\")\n",
    "\n",
    "df[['Year', 'Quarter', 'Time_Index', 'Quarter_Sin', 'Quarter_Cos']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for target variable (Naƒüd_pul_kredit_satƒ±≈üƒ±)\n",
    "target_col = 'Naƒüd_pul_kredit_satƒ±≈üƒ±'\n",
    "\n",
    "if target_col in df.columns:\n",
    "    # Lag features\n",
    "    df['Lag_1'] = df[target_col].shift(1)\n",
    "    df['Lag_2'] = df[target_col].shift(2)\n",
    "    df['Lag_3'] = df[target_col].shift(3)\n",
    "    df['Lag_4'] = df[target_col].shift(4)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['Rolling_Mean_2'] = df[target_col].rolling(window=2).mean()\n",
    "    df['Rolling_Mean_3'] = df[target_col].rolling(window=3).mean()\n",
    "    df['Rolling_Mean_4'] = df[target_col].rolling(window=4).mean()\n",
    "    \n",
    "    df['Rolling_Std_2'] = df[target_col].rolling(window=2).std()\n",
    "    df['Rolling_Std_3'] = df[target_col].rolling(window=3).std()\n",
    "    df['Rolling_Std_4'] = df[target_col].rolling(window=4).std()\n",
    "    \n",
    "    # Difference features\n",
    "    df['Diff_1'] = df[target_col].diff(1)\n",
    "    df['Diff_4'] = df[target_col].diff(4)  # Year-over-year change\n",
    "    \n",
    "    print(\"‚úÖ Lag and rolling features created\")\n",
    "    print(\"\\nüìä New Features:\")\n",
    "    print(\"  Lag Features: Lag_1, Lag_2, Lag_3, Lag_4\")\n",
    "    print(\"  Rolling Means: Rolling_Mean_2, Rolling_Mean_3, Rolling_Mean_4\")\n",
    "    print(\"  Rolling Std: Rolling_Std_2, Rolling_Std_3, Rolling_Std_4\")\n",
    "    print(\"  Differences: Diff_1 (quarter-over-quarter), Diff_4 (year-over-year)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: Target column '{target_col}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"üîç Duplicate Rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Removing duplicates...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úÖ Duplicates removed. New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite values\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "inf_counts = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    inf_count = np.isinf(df[col]).sum()\n",
    "    if inf_count > 0:\n",
    "        inf_counts[col] = inf_count\n",
    "\n",
    "if inf_counts:\n",
    "    print(\"‚ö†Ô∏è Infinite values found:\")\n",
    "    for col, count in inf_counts.items():\n",
    "        print(f\"  {col}: {count}\")\n",
    "    \n",
    "    # Replace infinite values with NaN\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    print(\"\\n‚úÖ Infinite values replaced with NaN\")\n",
    "else:\n",
    "    print(\"‚úÖ No infinite values found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display updated missing values after feature engineering\n",
    "print(\"üîç Missing Values After Feature Engineering:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_summary = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary)\n",
    "else:\n",
    "    print(\"‚úÖ No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target variable over time\n",
    "if target_col in df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # Time series plot\n",
    "    ax1 = axes[0, 0]\n",
    "    df_valid = df[df[target_col].notna()]\n",
    "    ax1.plot(df_valid['Time_Index'], df_valid[target_col], marker='o', linewidth=2, markersize=6)\n",
    "    ax1.set_title('Loan Sales Over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Time Index')\n",
    "    ax1.set_ylabel('Loan Sales (AZN)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(df_valid[target_col], bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax2.set_title('Distribution of Loan Sales', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Loan Sales (AZN)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot by quarter\n",
    "    ax3 = axes[1, 0]\n",
    "    df_valid.boxplot(column=target_col, by='Quarter', ax=ax3)\n",
    "    ax3.set_title('Loan Sales by Quarter', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Quarter')\n",
    "    ax3.set_ylabel('Loan Sales (AZN)')\n",
    "    plt.suptitle('')  # Remove auto-generated title\n",
    "    \n",
    "    # Year-over-year growth\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'Diff_4' in df.columns:\n",
    "        df_diff = df[df['Diff_4'].notna()]\n",
    "        ax4.bar(df_diff['Time_Index'], df_diff['Diff_4'], alpha=0.7)\n",
    "        ax4.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "        ax4.set_title('Year-over-Year Change', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Time Index')\n",
    "        ax4.set_ylabel('YoY Change (AZN)')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nüìä Target Variable Statistics:\")\n",
    "    print(f\"  Mean: {df_valid[target_col].mean():,.2f} AZN\")\n",
    "    print(f\"  Median: {df_valid[target_col].median():,.2f} AZN\")\n",
    "    print(f\"  Std Dev: {df_valid[target_col].std():,.2f} AZN\")\n",
    "    print(f\"  Min: {df_valid[target_col].min():,.2f} AZN\")\n",
    "    print(f\"  Max: {df_valid[target_col].max():,.2f} AZN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to both locations\n",
    "print(\"üíæ Saving processed data...\\n\")\n",
    "\n",
    "# Save to notebooks/data (for ML training)\n",
    "df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "print(f\"‚úÖ Saved to: {PROCESSED_DATA_PATH}\")\n",
    "\n",
    "# Save to dashboard public folder (for API)\n",
    "df.to_csv(DASHBOARD_DATA_PATH, index=False)\n",
    "print(f\"‚úÖ Saved to: {DASHBOARD_DATA_PATH}\")\n",
    "\n",
    "print(f\"\\nüìä Final Dataset:\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Rows: {df.shape[0]}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final column list\n",
    "print(\"üìã Final Column List:\\n\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of final data\n",
    "print(\"üìä Sample of Processed Data:\\n\")\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"=\"*80)\n",
    "print(\"DATA PREPARATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä DATASET OVERVIEW:\")\n",
    "print(f\"  Original Shape: {df_raw.shape}\")\n",
    "print(f\"  Final Shape: {df.shape}\")\n",
    "print(f\"  New Features Created: {df.shape[1] - df_raw.shape[1]}\")\n",
    "\n",
    "print(\"\\nüìÖ TIME PERIOD:\")\n",
    "print(f\"  Start: {df['Year'].min()}-Q{df['Quarter'].min()}\")\n",
    "print(f\"  End: {df['Year'].max()}-Q{df['Quarter'].max()}\")\n",
    "print(f\"  Total Quarters: {len(df[df['Year'].notna()])}\")\n",
    "\n",
    "print(\"\\nüìà TARGET VARIABLE (Naƒüd_pul_kredit_satƒ±≈üƒ±):\")\n",
    "if target_col in df.columns:\n",
    "    valid_target = df[df[target_col].notna()][target_col]\n",
    "    print(f\"  Valid Records: {len(valid_target)}\")\n",
    "    print(f\"  Mean: {valid_target.mean():,.2f} AZN\")\n",
    "    print(f\"  Std Dev: {valid_target.std():,.2f} AZN\")\n",
    "    print(f\"  Min: {valid_target.min():,.2f} AZN\")\n",
    "    print(f\"  Max: {valid_target.max():,.2f} AZN\")\n",
    "\n",
    "print(\"\\nüîß FEATURE TYPES:\")\n",
    "print(f\"  Original Features: {len(df_raw.columns)}\")\n",
    "print(f\"  Time Features: 5 (Year, Quarter, Time_Index, Quarter_Sin, Quarter_Cos)\")\n",
    "print(f\"  Lag Features: 4 (Lag_1 to Lag_4)\")\n",
    "print(f\"  Rolling Features: 6 (Rolling means and stds)\")\n",
    "print(f\"  Difference Features: 2 (Diff_1, Diff_4)\")\n",
    "print(f\"  Total Features: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nüìÅ FILES SAVED:\")\n",
    "print(f\"  1. {PROCESSED_DATA_PATH}\")\n",
    "print(f\"  2. {DASHBOARD_DATA_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DATA PREPARATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Exploratory Data Analysis (EDA)**: Create `02_eda.ipynb` for detailed analysis\n",
    "2. **Model Training**: Create `03_model_training.ipynb` for ML models\n",
    "3. **Model Evaluation**: Create `04_model_evaluation.ipynb` for comparing models\n",
    "4. **Forecasting**: Use the trained models to make predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
