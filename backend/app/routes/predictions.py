"""
ProqnozlaÅŸdÄ±rma vÉ™ GÉ™lÉ™cÉ™k TÉ™xminlÉ™ri Endpoint-lÉ™ri
Predictions and Forecasting Routes
"""

from fastapi import APIRouter, HTTPException, Query
from typing import Dict, Any
import pandas as pd
import numpy as np
from pathlib import Path
import pickle
import json
import math

from app.utils.data_loader import data_loader

router = APIRouter()

def clean_value(val):
    """Clean value for JSON serialization"""
    if pd.isna(val) or (isinstance(val, (int, float)) and math.isinf(val)):
        return 0.0
    if isinstance(val, (np.integer, np.floating)):
        return float(val)
    if isinstance(val, np.bool_):
        return bool(val)
    return val

# Model paths
# Use environment variable to determine path or auto-detect
import os
if os.getenv('ENVIRONMENT') == 'production':
    # Docker: /app/app/routes/predictions.py -> /app/notebooks/predictions/models
    MODELS_DIR = Path(__file__).parent.parent.parent / "notebooks" / "predictions" / "models"
else:
    # Local: backend/app/routes/predictions.py -> notebooks/predictions/models
    MODELS_DIR = Path(__file__).parent.parent.parent.parent / "notebooks" / "predictions" / "models"


@router.get("/simple-forecast", response_model=Dict[str, Any])
async def get_simple_forecast(
    periods: int = Query(default=4, ge=1, le=12, description="Proqnoz dÃ¶vrlÉ™ri (1-12 rÃ¼b)")
):
    """
    ğŸ”® SadÉ™ Proqnoz

    Moving Average vÉ™ Exponential Smoothing É™sasÄ±nda sadÉ™ proqnoz

    Parameters:
    - periods: GÉ™lÉ™cÉ™k neÃ§É™ rÃ¼b Ã¼Ã§Ã¼n proqnoz (1-12 arasÄ±)
    """
    df = data_loader.df

    # Filter out rows with empty/NaN target values
    df_valid = df[df['NaÄŸd_pul_kredit_satÄ±ÅŸÄ±'].notna()].copy()
    y = df_valid['NaÄŸd_pul_kredit_satÄ±ÅŸÄ±'].values

    # Son dÉ™yÉ™rlÉ™r (from last valid row)
    last_period = df_valid['RÃ¼blÉ™r'].iloc[-1]
    last_year = df_valid['Year'].iloc[-1]
    last_quarter = df_valid['Quarter'].iloc[-1]
    last_value = y[-1]

    # 1. Moving Average (son 4 rÃ¼b)
    ma_4 = np.mean(y[-4:])

    # 2. Weighted Moving Average (son 4 rÃ¼b, Ã§É™kilÉ™r: 0.4, 0.3, 0.2, 0.1)
    weights = np.array([0.1, 0.2, 0.3, 0.4])
    wma_4 = np.sum(y[-4:] * weights)

    # 3. Exponential Smoothing (alpha=0.3)
    alpha = 0.3
    ema = y[0]
    for val in y[1:]:
        ema = alpha * val + (1 - alpha) * ema

    # 4. Trend-based forecast (son 8 rÃ¼b Ã¼zrÉ™ xÉ™tti trend)
    recent_periods = np.arange(len(y[-8:]))
    recent_values = y[-8:]
    trend_coef = np.polyfit(recent_periods, recent_values, 1)
    trend_slope = trend_coef[0]
    trend_intercept = trend_coef[1]

    # Proqnozlar
    forecasts = []
    for i in range(1, periods + 1):
        # DÃ¶vrÃ¼ hesabla
        quarter = ((last_quarter + i - 1) % 4) + 1
        year = last_year + (last_quarter + i - 1) // 4
        period_name = f"{year}-Q{quarter}"

        # MÃ¼xtÉ™lif metodlarla proqnozlar
        ma_forecast = ma_4
        wma_forecast = wma_4
        ema_forecast = ema
        trend_forecast = trend_slope * (len(y) + i - 1) + trend_intercept

        # KombinÉ™ olunmuÅŸ proqnoz (bÃ¼tÃ¼n metodlarÄ±n ortalamasÄ±)
        combined_forecast = np.mean([ma_forecast, wma_forecast, ema_forecast, trend_forecast])

        # Confidence interval (sadÉ™ yanaÅŸma - son dÉ™yÉ™rlÉ™rin standart sapmasÄ±)
        std = np.std(y[-8:])
        lower_bound = combined_forecast - 1.96 * std  # 95% CI
        upper_bound = combined_forecast + 1.96 * std

        forecasts.append({
            "dÃ¶vr": period_name,
            "il": int(year),
            "rÃ¼b": int(quarter),
            "kombinÉ™_proqnoz": round(clean_value(combined_forecast), 2),
            "aÅŸaÄŸÄ±_sÉ™rhÉ™d_95": round(clean_value(lower_bound), 2),
            "yuxarÄ±_sÉ™rhÉ™d_95": round(clean_value(upper_bound), 2),
            "metodlar": {
                "moving_average": round(clean_value(ma_forecast), 2),
                "weighted_ma": round(clean_value(wma_forecast), 2),
                "exponential_smoothing": round(clean_value(ema_forecast), 2),
                "trend_based": round(clean_value(trend_forecast), 2)
            }
        })

    # MetodlarÄ±n izahÄ±
    method_explanations = {
        "moving_average": {
            "ad": "HÉ™rÉ™kÉ™tli Ortalama (Moving Average)",
            "tÉ™svir": "Son 4 rÃ¼bÃ¼n sadÉ™ ortalamasÄ±",
            "Ã¼stÃ¼nlÃ¼k": "SadÉ™ vÉ™ anlaÅŸÄ±lan",
            "Ã§atÄ±ÅŸmazlÄ±q": "Trend vÉ™ mÃ¶vsÃ¼miliyi nÉ™zÉ™rÉ™ almÄ±r",
            "uyÄŸunluq": "Sabit mÉ™lumatlar Ã¼Ã§Ã¼n"
        },
        "weighted_ma": {
            "ad": "Ã‡É™kili HÉ™rÉ™kÉ™tli Ortalama (Weighted MA)",
            "tÉ™svir": "YaxÄ±n dÃ¶vrlÉ™rin Ã§É™kisi daha Ã§oxdur (40%, 30%, 20%, 10%)",
            "Ã¼stÃ¼nlÃ¼k": "Son dÉ™yiÅŸikliklÉ™rÉ™ daha hÉ™ssas",
            "Ã§atÄ±ÅŸmazlÄ±q": "Ã‡É™kilÉ™rin seÃ§imi subyektivdir",
            "uyÄŸunluq": "Trendli mÉ™lumatlar Ã¼Ã§Ã¼n"
        },
        "exponential_smoothing": {
            "ad": "Eksponensial HamarlaÅŸdÄ±rma",
            "tÉ™svir": "BÃ¼tÃ¼n keÃ§miÅŸ dÉ™yÉ™rlÉ™r nÉ™zÉ™rÉ™ alÄ±nÄ±r, lakin yaxÄ±n dÃ¶vrlÉ™rin tÉ™siri daha gÃ¼clÃ¼dÃ¼r (Î±=0.3)",
            "Ã¼stÃ¼nlÃ¼k": "BÃ¼tÃ¼n tarixi nÉ™zÉ™rÉ™ alÄ±r",
            "Ã§atÄ±ÅŸmazlÄ±q": "Alpha parametrinin seÃ§imi mÃ¼hÃ¼mdÃ¼r",
            "uyÄŸunluq": "Uzun tarixli mÉ™lumatlar Ã¼Ã§Ã¼n"
        },
        "trend_based": {
            "ad": "Trend ÆsaslÄ± Proqnoz",
            "tÉ™svir": "Son 8 rÃ¼bÃ¼n xÉ™tti trendi É™sasÄ±nda",
            "Ã¼stÃ¼nlÃ¼k": "Trend davam edÉ™rsÉ™ dÉ™qiqdir",
            "Ã§atÄ±ÅŸmazlÄ±q": "QÄ±rÄ±lma nÃ¶qtÉ™lÉ™rini tutmur",
            "uyÄŸunluq": "GÃ¼clÃ¼ trend olan mÉ™lumatlar Ã¼Ã§Ã¼n"
        }
    }

    # Proqnoz keyfiyyÉ™ti
    actual_vs_pred = []
    for i in range(4, len(y)):
        actual = y[i]
        pred_ma = np.mean(y[i-4:i])
        actual_vs_pred.append({
            "faktiki": clean_value(actual),
            "proqnoz": clean_value(pred_ma),
            "xÉ™ta": clean_value(abs(actual - pred_ma)),
            "xÉ™ta_faizi": clean_value(abs(actual - pred_ma) / actual * 100 if actual != 0 else 0)
        })

    avg_error = clean_value(np.mean([x["xÉ™ta"] for x in actual_vs_pred]))
    avg_error_pct = clean_value(np.mean([x["xÉ™ta_faizi"] for x in actual_vs_pred]))

    return {
        "proqnoz_nÉ™dir": {
            "tÉ™svir": "ProqnozlaÅŸdÄ±rma - keÃ§miÅŸ mÉ™lumatlar É™sasÄ±nda gÉ™lÉ™cÉ™k dÉ™yÉ™rlÉ™ri tÉ™xmin etmÉ™ prosesidir.",
            "niyÉ™_vacibdir": [
                "GÉ™lÉ™cÉ™k planlaÅŸdÄ±rma vÉ™ bÃ¼dcÉ™ tÉ™rtibatÄ± Ã¼Ã§Ã¼n",
                "ResurslarÄ±n sÉ™mÉ™rÉ™li bÃ¶lÃ¼ÅŸdÃ¼rÃ¼lmÉ™si Ã¼Ã§Ã¼n",
                "RisklÉ™rin É™vvÉ™lcÉ™dÉ™n mÃ¼É™yyÉ™n edilmÉ™si Ã¼Ã§Ã¼n",
                "Ä°ÅŸ strategiyalarÄ±nÄ±n hazÄ±rlanmasÄ± Ã¼Ã§Ã¼n"
            ],
            "nÉ™_zaman_istifadÉ™": "Zaman seriyasÄ± mÉ™lumatlarÄ±nda gÉ™lÉ™cÉ™k dÉ™yÉ™rlÉ™ri tÉ™xmin etmÉ™k istÉ™dikdÉ™"
        },
        "cari_vÉ™ziyyÉ™t": {
            "son_dÃ¶vr": last_period,
            "son_dÉ™yÉ™r": round(clean_value(last_value), 2),
            "son_4_rÃ¼b_ortalama": round(clean_value(ma_4), 2),
            "dÉ™yiÅŸiklik": round(clean_value(last_value - ma_4), 2),
            "dÉ™yiÅŸiklik_faizi": round(clean_value((last_value - ma_4) / ma_4 * 100 if ma_4 != 0 else 0), 2)
        },
        "proqnozlar": forecasts,
        "metodlar": method_explanations,
        "dÉ™qiqlik_tÉ™hlili": {
            "ortalama_xÉ™ta": round(avg_error, 2),
            "ortalama_xÉ™ta_faizi": round(avg_error_pct, 2),
            "test_edilmiÅŸ_proqnozlar": len(actual_vs_pred),
            "qeyd": "Bu dÉ™qiqlik gÃ¶stÉ™ricilÉ™ri keÃ§miÅŸ mÉ™lumatlar Ã¼zrÉ™ Moving Average metodunun performansÄ±nÄ± É™ks etdirir"
        },
        "praktik_tÉ™fsir": {
            "É™sas_nÉ™ticÉ™": f"NÃ¶vbÉ™ti rÃ¼b Ã¼Ã§Ã¼n gÃ¶zlÉ™nilÉ™n dÉ™yÉ™r {round(forecasts[0]['kombinÉ™_proqnoz'], 2):,.0f} manat civarÄ±nda olacaq",
            "etibarlÄ±lÄ±q_aralÄ±ÄŸÄ±": f"95% ehtimalla {round(forecasts[0]['aÅŸaÄŸÄ±_sÉ™rhÉ™d_95'], 2):,.0f} - {round(forecasts[0]['yuxarÄ±_sÉ™rhÉ™d_95'], 2):,.0f} manat arasÄ±nda",
            "tÃ¶vsiyÉ™": "KombinÉ™ proqnoz daha etibarlÄ±dÄ±r, Ã§Ã¼nki mÃ¼xtÉ™lif metodlarÄ±n gÃ¼clÃ¼ tÉ™rÉ™flÉ™rini birlÉ™ÅŸdirir"
        }
    }


@router.get("/seasonal-forecast", response_model=Dict[str, Any])
async def get_seasonal_forecast(
    periods: int = Query(default=4, ge=1, le=8, description="Proqnoz dÃ¶vrlÉ™ri")
):
    """
    ğŸ“… MÃ¶vsÃ¼mi Proqnoz

    MÃ¶vsÃ¼miliyi nÉ™zÉ™rÉ™ alan proqnoz modeli
    RÃ¼blÉ™r arasÄ± fÉ™rqlÉ™ri vÉ™ tÉ™krar edilÉ™n nÃ¼munÉ™lÉ™ri tutur
    """
    df = data_loader.df
    y = df['NaÄŸd_pul_kredit_satÄ±ÅŸÄ±'].values
    quarters = df['Quarter'].values

    last_period = df['RÃ¼blÉ™r'].iloc[-1]
    last_year = df['Year'].iloc[-1]
    last_quarter = df['Quarter'].iloc[-1]

    # HÉ™r rÃ¼b Ã¼Ã§Ã¼n ortalama
    seasonal_avg = {}
    for q in [1, 2, 3, 4]:
        q_values = y[quarters == q]
        seasonal_avg[q] = np.mean(q_values)

    # Ãœmumi ortalama
    overall_avg = np.mean(y)

    # Seasonal indices (mÃ¶vsÃ¼milik indekslÉ™ri)
    seasonal_indices = {}
    for q in [1, 2, 3, 4]:
        seasonal_indices[q] = seasonal_avg[q] / overall_avg

    # Trend (son 12 rÃ¼b)
    recent_y = y[-12:] if len(y) >= 12 else y
    recent_x = np.arange(len(recent_y))
    trend_coef = np.polyfit(recent_x, recent_y, 1)
    trend_slope = trend_coef[0]
    trend_intercept = trend_coef[1]

    # Proqnozlar
    forecasts = []
    for i in range(1, periods + 1):
        quarter = ((last_quarter + i - 1) % 4) + 1
        year = last_year + (last_quarter + i - 1) // 4
        period_name = f"{year}-Q{quarter}"

        # Trend dÉ™yÉ™ri
        trend_value = trend_slope * (len(y) + i - 1) + trend_intercept

        # MÃ¶vsÃ¼milik tÉ™tbiq et
        seasonal_forecast = trend_value * seasonal_indices[quarter]

        # Confidence interval
        # HÉ™r rÃ¼bÃ¼n keÃ§miÅŸ dÉ™yÉ™rlÉ™rinin variasiyasÄ±
        q_historical = y[quarters == quarter]
        q_std = np.std(q_historical)

        lower_bound = seasonal_forecast - 1.96 * q_std
        upper_bound = seasonal_forecast + 1.96 * q_std

        forecasts.append({
            "dÃ¶vr": period_name,
            "il": int(year),
            "rÃ¼b": int(quarter),
            "proqnoz": round(seasonal_forecast, 2),
            "aÅŸaÄŸÄ±_sÉ™rhÉ™d_95": round(lower_bound, 2),
            "yuxarÄ±_sÉ™rhÉ™d_95": round(upper_bound, 2),
            "komponenlÉ™r": {
                "trend_komponenti": round(trend_value, 2),
                "mÃ¶vsÃ¼mi_indeks": round(seasonal_indices[quarter], 4),
                "mÃ¶vsÃ¼mi_tÉ™sir": round((seasonal_indices[quarter] - 1) * 100, 2)
            }
        })

    # MÃ¶vsÃ¼milik tÉ™hlili
    seasonal_analysis = {}
    for q in [1, 2, 3, 4]:
        q_values = y[quarters == q]
        seasonal_analysis[f"Q{q}"] = {
            "ortalama": round(seasonal_avg[q], 2),
            "indeks": round(seasonal_indices[q], 4),
            "Ã¼mumi_ortalamadan_fÉ™rq": round((seasonal_indices[q] - 1) * 100, 2),
            "izah": "Ãœmumi ortalamadan yÃ¼ksÉ™k" if seasonal_indices[q] > 1 else "Ãœmumi ortalamadan aÅŸaÄŸÄ±",
            "keÃ§miÅŸ_dÉ™yÉ™rlÉ™r_sayÄ±": len(q_values),
            "standart_sapma": round(np.std(q_values), 2)
        }

    return {
        "mÃ¶vsÃ¼mi_proqnoz_nÉ™dir": {
            "tÉ™svir": "MÃ¶vsÃ¼mi proqnozlaÅŸdÄ±rma - il iÃ§indÉ™ tÉ™krar edilÉ™n nÃ¼munÉ™lÉ™ri (rÃ¼blÉ™r arasÄ± fÉ™rqlÉ™ri) nÉ™zÉ™rÉ™ alan proqnoz metodudur.",
            "komponentlÉ™r": [
                "Trend: Ãœmumi artÄ±m vÉ™ ya azalma istiqamÉ™ti",
                "MÃ¶vsÃ¼mililik: RÃ¼blÉ™r arasÄ± tÉ™krar edilÉ™n fÉ™rqlÉ™r",
                "TÉ™sadÃ¼fi: Ä°zah edilmÉ™yÉ™n variasiya"
            ],
            "Ã¼stÃ¼nlÃ¼k": "Kredit satÄ±ÅŸÄ± kimi mÃ¶vsÃ¼mi xarakterli mÉ™lumatlar Ã¼Ã§Ã¼n daha dÉ™qiqdir",
            "nÉ™_zaman_istifadÉ™": "MÉ™lumatlar aydÄ±n mÃ¶vsÃ¼mi nÃ¼munÉ™ gÃ¶stÉ™rdikdÉ™"
        },
        "mÃ¶vsÃ¼milik_tÉ™hlili": seasonal_analysis,
        "trend_mÉ™lumatÄ±": {
            "istiqamÉ™t": "ArtÄ±m" if trend_slope > 0 else "Azalma",
            "rÃ¼b_baÅŸÄ±na_dÉ™yiÅŸmÉ™": round(trend_slope, 2),
            "il_baÅŸÄ±na_dÉ™yiÅŸmÉ™": round(trend_slope * 4, 2),
            "trend_gÃ¼cÃ¼": "GÃ¼clÃ¼" if abs(trend_slope) > 1000 else "Orta" if abs(trend_slope) > 500 else "ZÉ™if"
        },
        "proqnozlar": forecasts,
        "praktik_tÉ™fsir": {
            "É™n_gÃ¼clÃ¼_rÃ¼b": f"Q{max(seasonal_indices, key=seasonal_indices.get)}",
            "É™n_zÉ™if_rÃ¼b": f"Q{min(seasonal_indices, key=seasonal_indices.get)}",
            "mÃ¶vsÃ¼mi_fÉ™rq": round((max(seasonal_indices.values()) - min(seasonal_indices.values())) * 100, 2),
            "tÃ¶vsiyÉ™": "MÃ¶vsÃ¼mi nÃ¼munÉ™lÉ™r ardÄ±cÄ±l olaraq, planlaÅŸdÄ±rmada hÉ™r rÃ¼bÃ¼n xÃ¼susiyyÉ™tlÉ™rini nÉ™zÉ™rÉ™ alÄ±n"
        }
    }


@router.get("/confidence-levels", response_model=Dict[str, Any])
async def get_confidence_levels():
    """
    ğŸ¯ Etibar SÉ™viyyÉ™lÉ™ri vÉ™ Proqnoz DÉ™qiqliyi

    ProqnozlarÄ±n nÉ™ qÉ™dÉ™r etibarlÄ± olduÄŸunu anlamaq Ã¼Ã§Ã¼n mÃ¼xtÉ™lif gÃ¶stÉ™ricilÉ™r
    """
    df = data_loader.df
    y = df['NaÄŸd_pul_kredit_satÄ±ÅŸÄ±'].values

    # Son 4 rÃ¼bÉ™ É™saslanan sadÉ™ proqnoz keyfiyyÉ™ti
    errors = []
    for i in range(8, len(y)):  # Son 14 proqnoz (22-8=14)
        actual = y[i]
        predicted = np.mean(y[i-4:i])
        error = actual - predicted
        abs_error = abs(error)
        pct_error = abs_error / actual * 100 if actual != 0 else 0

        errors.append({
            "xÉ™ta": error,
            "mÃ¼tlÉ™q_xÉ™ta": abs_error,
            "faiz_xÉ™ta": pct_error
        })

    # Metrics
    mae = np.mean([e["mÃ¼tlÉ™q_xÉ™ta"] for e in errors])
    rmse = np.sqrt(np.mean([e["xÉ™ta"]**2 for e in errors]))
    mape = np.mean([e["faiz_xÉ™ta"] for e in errors])

    # Forecast accuracy classification
    if mape < 10:
        accuracy_class = "Ã‡ox YÃ¼ksÉ™k"
        description = "Proqnozlar Ã§ox etibarlÄ±dÄ±r"
    elif mape < 20:
        accuracy_class = "YÃ¼ksÉ™k"
        description = "Proqnozlar yaxÅŸÄ± dÉ™qiqliyÉ™ malikdir"
    elif mape < 30:
        accuracy_class = "Orta"
        description = "Proqnozlar qÉ™bul edilÉ™ bilÉ™r, lakin ehtiyatla yanaÅŸÄ±n"
    else:
        accuracy_class = "AÅŸaÄŸÄ±"
        description = "Proqnozlar az etibarlÄ±dÄ±r, É™lavÉ™ tÉ™kmillÉ™ÅŸdirmÉ™ lazÄ±mdÄ±r"

    # Confidence intervals
    std_error = np.std([e["xÉ™ta"] for e in errors])

    confidence_intervals = {
        "68%": {
            "aralÄ±q": f"Â±{round(std_error, 2):,.0f} manat",
            "izah": "ProqnozlarÄ±n tÉ™xminÉ™n 68%-i bu aralÄ±qda olacaq (1 standart sapma)"
        },
        "95%": {
            "aralÄ±q": f"Â±{round(1.96 * std_error, 2):,.0f} manat",
            "izah": "ProqnozlarÄ±n tÉ™xminÉ™n 95%-i bu aralÄ±qda olacaq (1.96 standart sapma)"
        },
        "99%": {
            "aralÄ±q": f"Â±{round(2.58 * std_error, 2):,.0f} manat",
            "izah": "ProqnozlarÄ±n tÉ™xminÉ™n 99%-i bu aralÄ±qda olacaq (2.58 standart sapma)"
        }
    }

    return {
        "etibar_sÉ™viyyÉ™lÉ™ri_nÉ™dir": {
            "tÉ™svir": "Etibar sÉ™viyyÉ™si proqnozun nÉ™ qÉ™dÉ™r etibarlÄ± olduÄŸunu gÃ¶stÉ™rir. 95% etibar sÉ™viyyÉ™si o demÉ™kdir ki, 100 proqnozdan 95-i bu aralÄ±qda olacaq.",
            "praktik_istifadÉ™": [
                "Risk idarÉ™etmÉ™si Ã¼Ã§Ã¼n: Æn pis vÉ™ É™n yaxÅŸÄ± ssenarilÉ™ri mÃ¼É™yyÉ™n edin",
                "PlanlaÅŸdÄ±rma Ã¼Ã§Ã¼n: Ehtiyat fondlarÄ± vÉ™ resurslarÄ± hesablayÄ±n",
                "QÉ™rar qÉ™bul etmÉ™ Ã¼Ã§Ã¼n: Proqnozun etibarlÄ±lÄ±ÄŸÄ±nÄ± qiymÉ™tlÉ™ndirin"
            ],
            "seÃ§im": "95% etibar sÉ™viyyÉ™si É™n Ã§ox istifadÉ™ olunur (elmi standart)"
        },
        "dÉ™qiqlik_gÃ¶stÉ™ricilÉ™ri": {
            "MAE": {
                "dÉ™yÉ™r": round(mae, 2),
                "ad": "Mean Absolute Error (Ortalama MÃ¼tlÉ™q XÉ™ta)",
                "izah": "Ortalama olaraq proqnozlar faktiki dÉ™yÉ™rdÉ™n bu qÉ™dÉ™r fÉ™rqlÉ™nir",
                "vahid": "manat"
            },
            "RMSE": {
                "dÉ™yÉ™r": round(rmse, 2),
                "ad": "Root Mean Squared Error (KÃ¶k Ortalama Kvadrat XÉ™ta)",
                "izah": "BÃ¶yÃ¼k xÉ™talarÄ± daha Ã§ox cÉ™zalandÄ±ran Ã¶lÃ§Ã¼. MAE-dÉ™n bÃ¶yÃ¼kdÃ¼rsÉ™, bÉ™zi proqnozlar Ã§ox sÉ™hvdir",
                "vahid": "manat"
            },
            "MAPE": {
                "dÉ™yÉ™r": round(mape, 2),
                "ad": "Mean Absolute Percentage Error (Ortalama MÃ¼tlÉ™q Faiz XÉ™ta)",
                "izah": "XÉ™tanÄ±n faktiki dÉ™yÉ™rÉ™ nisbÉ™tÉ™n faizi. MÃ¼xtÉ™lif miqyaslÄ± mÉ™lumatlarÄ± mÃ¼qayisÉ™ etmÉ™k Ã¼Ã§Ã¼n",
                "vahid": "%"
            }
        },
        "proqnoz_keyfiyyÉ™ti": {
            "sinif": accuracy_class,
            "tÉ™svir": description,
            "É™saslandÄ±rma": f"MAPE = {round(mape, 2)}% ({accuracy_class} dÉ™qiqlik)",
            "standart": {
                "Ã‡ox YÃ¼ksÉ™k": "MAPE < 10%",
                "YÃ¼ksÉ™k": "10% â‰¤ MAPE < 20%",
                "Orta": "20% â‰¤ MAPE < 30%",
                "AÅŸaÄŸÄ±": "MAPE â‰¥ 30%"
            }
        },
        "etibar_aralÄ±qlarÄ±": confidence_intervals,
        "test_edilÉ™n_proqnozlar": {
            "sayÄ±": len(errors),
            "ortalama_xÉ™ta": round(np.mean([e["xÉ™ta"] for e in errors]), 2),
            "pozitiv_xÉ™talar": len([e for e in errors if e["xÉ™ta"] > 0]),
            "neqativ_xÉ™talar": len([e for e in errors if e["xÉ™ta"] < 0]),
            "izah": "Pozitiv xÉ™ta: proqnoz faktikidÉ™n kiÃ§ikdir. Neqativ xÉ™ta: proqnoz faktikidÉ™n bÃ¶yÃ¼kdÃ¼r"
        },
        "praktik_tÃ¶vsiyÉ™": {
            "planlaÅŸdÄ±rma_Ã¼Ã§Ã¼n": f"NÃ¶vbÉ™ti rÃ¼b Ã¼Ã§Ã¼n proqnozu Â±{round(1.96 * std_error, 2):,.0f} manat etibar aralÄ±ÄŸÄ± ilÉ™ istifadÉ™ edin",
            "risk_idarÉ™etmÉ™si": f"Æn pis ssenari Ã¼Ã§Ã¼n proqnozdan {round(1.96 * std_error, 2):,.0f} manat aÅŸaÄŸÄ± dÉ™yÉ™r nÉ™zÉ™rÉ™ alÄ±n",
            "tÉ™kmillÉ™ÅŸdirmÉ™": "ÆgÉ™r MAPE > 20% isÉ™, É™lavÉ™ dÉ™yiÅŸÉ™nlÉ™r É™lavÉ™ edin vÉ™ ya daha mÃ¼rÉ™kkÉ™b model istifadÉ™ edin"
        }
    }


@router.get("/advanced-models-info", response_model=Dict[str, Any])
async def get_advanced_models_info():
    """
    ğŸ¤– Advanced ML Models Information

    Returns information about all trained advanced models
    """
    try:
        model_info_path = MODELS_DIR / "model_info.json"

        if not model_info_path.exists():
            return {
                "status": "not_trained",
                "message": "Advanced models have not been trained yet. Please run the training notebook first.",
                "notebook_path": "notebooks/predictions/advanced_forecasting_models.ipynb"
            }

        with open(model_info_path, 'r', encoding='utf-8') as f:
            model_info = json.load(f)

        return {
            "status": "ready",
            "models": model_info['models'],
            "best_model": model_info['best_model'],
            "training_date": model_info['training_date']
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error loading model info: {str(e)}")


@router.post("/advanced-forecast", response_model=Dict[str, Any])
async def get_advanced_forecast(
    model_name: str = Query(..., description="Model: random_forest, xgboost, arima, sarima, sarimax"),
    n_periods: int = Query(default=4, ge=1, le=8, description="Number of periods to forecast")
):
    """
    ğŸš€ Advanced Model Forecasting

    Make predictions using trained ML/Time Series models
    """
    try:
        # Check if models exist
        if not MODELS_DIR.exists():
            raise HTTPException(
                status_code=404,
                detail="Models directory not found. Please train models first."
            )

        # Load model info
        model_info_path = MODELS_DIR / "model_info.json"
        if not model_info_path.exists():
            raise HTTPException(
                status_code=404,
                detail="Models not trained yet. Please run the training notebook."
            )

        with open(model_info_path, 'r', encoding='utf-8') as f:
            model_info = json.load(f)

        # Find model details
        model_details = next((m for m in model_info['models'] if m['id'] == model_name), None)
        if not model_details:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid model name: {model_name}. Available: random_forest, xgboost, arima, sarima, sarimax"
            )

        df = data_loader.df

        # Prepare forecast based on model type
        if model_name in ['random_forest', 'xgboost']:
            # Load ML model and scaler
            model_path = MODELS_DIR / f"{model_name}.pkl"
            scaler_path = MODELS_DIR / "scaler.pkl"

            with open(model_path, 'rb') as f:
                model = pickle.load(f)
            with open(scaler_path, 'rb') as f:
                scaler = pickle.load(f)

            # Load feature importance
            fi_prefix = "rf" if model_name == "random_forest" else "xgb"
            fi_path = MODELS_DIR / f"{fi_prefix}_feature_importance.csv"
            feature_importance = pd.read_csv(fi_path).head(10).to_dict('records')

            # Simple prediction (using last known lags)
            # This is simplified - in production you'd do recursive forecasting
            last_values = df['NaÄŸd_pul_kredit_satÄ±ÅŸÄ±'].iloc[-4:].values
            last_year = df['Year'].iloc[-1]
            last_quarter = df['Quarter'].iloc[-1]

            forecasts = []
            for i in range(1, n_periods + 1):
                q = ((last_quarter + i - 1) % 4) + 1
                y = last_year + (last_quarter + i - 1) // 4

                # Create feature vector (simplified)
                features = {
                    'Year': y,
                    'Quarter': q,
                    'Time_Index': len(df) + i - 1,
                    'Quarter_Sin': np.sin(2 * np.pi * q / 4),
                    'Quarter_Cos': np.cos(2 * np.pi * q / 4),
                    'Lag_1': last_values[-1],
                    'Lag_2': last_values[-2],
                    'Lag_3': last_values[-3],
                    'Lag_4': last_values[-4] if len(last_values) > 3 else last_values[0],
                    'Rolling_Mean_2': np.mean(last_values[-2:]),
                    'Rolling_Mean_3': np.mean(last_values[-3:]),
                    'Rolling_Mean_4': np.mean(last_values[-4:]),
                    'Rolling_Std_2': np.std(last_values[-2:]),
                    'Rolling_Std_3': np.std(last_values[-3:]),
                    'Rolling_Std_4': np.std(last_values[-4:]),
                    'Diff_1': 0,
                    'Diff_4': 0
                }

                X = pd.DataFrame([features])
                X_scaled = scaler.transform(X)
                pred = model.predict(X_scaled)[0]

                # Simple confidence interval
                std = np.std(last_values)

                forecasts.append({
                    "dÃ¶vr": f"{y}-Q{q}",
                    "il": int(y),
                    "rÃ¼b": int(q),
                    "proqnoz": round(float(pred), 2),
                    "aÅŸaÄŸÄ±_sÉ™rhÉ™d_95": round(float(pred - 1.96 * std), 2),
                    "yuxarÄ±_sÉ™rhÉ™d_95": round(float(pred + 1.96 * std), 2)
                })

            return {
                "model": model_details,
                "proqnozlar": forecasts,
                "feature_importance": feature_importance,
                "model_type": "Machine Learning"
            }

        elif model_name in ['arima', 'sarima', 'sarimax']:
            # Load time series model
            from statsmodels.tsa.statespace.sarimax import SARIMAXResults
            from statsmodels.tsa.arima.model import ARIMAResults

            model_path = MODELS_DIR / f"{model_name}.pkl"

            if model_name == 'arima':
                model = ARIMAResults.load(model_path)
            else:
                model = SARIMAXResults.load(model_path)

            # Make forecast
            last_year = df['Year'].iloc[-1]
            last_quarter = df['Quarter'].iloc[-1]

            if model_name == 'sarimax':
                # Need exogenous variables for SARIMAX
                exog_future = []
                for i in range(1, n_periods + 1):
                    q = ((last_quarter + i - 1) % 4) + 1
                    y = last_year + (last_quarter + i - 1) // 4
                    exog_future.append({'Year': y, 'Quarter': q})

                exog_df = pd.DataFrame(exog_future)
                forecast_result = model.forecast(steps=n_periods, exog=exog_df)
                # Get confidence intervals with exog
                forecast_obj = model.get_forecast(steps=n_periods, exog=exog_df)
                forecast_ci = forecast_obj.conf_int()
            else:
                forecast_result = model.forecast(steps=n_periods)
                # Get confidence intervals without exog
                forecast_ci = model.get_forecast(steps=n_periods).conf_int()

            last_year = df['Year'].iloc[-1]
            last_quarter = df['Quarter'].iloc[-1]

            forecasts = []
            for i in range(n_periods):
                q = ((last_quarter + i) % 4) + 1
                y = last_year + (last_quarter + i) // 4

                forecasts.append({
                    "dÃ¶vr": f"{y}-Q{q}",
                    "il": int(y),
                    "rÃ¼b": int(q),
                    "proqnoz": round(float(forecast_result.iloc[i]), 2),
                    "aÅŸaÄŸÄ±_sÉ™rhÉ™d_95": round(float(forecast_ci.iloc[i, 0]), 2),
                    "yuxarÄ±_sÉ™rhÉ™d_95": round(float(forecast_ci.iloc[i, 1]), 2)
                })

            return {
                "model": model_details,
                "proqnozlar": forecasts,
                "model_type": "Time Series"
            }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Forecast error: {str(e)}")


@router.get("/model-comparison", response_model=Dict[str, Any])
async def get_model_comparison():
    """
    âš–ï¸ Model MÃ¼qayisÉ™si

    MÃ¼xtÉ™lif proqnoz modellÉ™rinin performans mÃ¼qayisÉ™si
    """
    df = data_loader.df
    y = df['NaÄŸd_pul_kredit_satÄ±ÅŸÄ±'].values
    quarters = df['Quarter'].values

    # Test set: son 4 rÃ¼b
    train_y = y[:-4]
    test_y = y[-4:]
    test_quarters = quarters[-4:]

    # Model 1: Naive (Son dÉ™yÉ™r)
    naive_pred = np.repeat(train_y[-1], 4)
    naive_mae = np.mean(np.abs(test_y - naive_pred))

    # Model 2: Moving Average (4 period)
    ma_pred = np.repeat(np.mean(train_y[-4:]), 4)
    ma_mae = np.mean(np.abs(test_y - ma_pred))

    # Model 3: Seasonal Naive
    seasonal_naive_pred = []
    for q in test_quarters:
        historical_q = train_y[quarters[:-4] == q]
        if len(historical_q) > 0:
            seasonal_naive_pred.append(historical_q[-1])
        else:
            seasonal_naive_pred.append(train_y[-1])
    seasonal_naive_pred = np.array(seasonal_naive_pred)
    seasonal_naive_mae = np.mean(np.abs(test_y - seasonal_naive_pred))

    # Model 4: Seasonal Average
    seasonal_avg_pred = []
    for q in test_quarters:
        historical_q = train_y[quarters[:-4] == q]
        if len(historical_q) > 0:
            seasonal_avg_pred.append(np.mean(historical_q))
        else:
            seasonal_avg_pred.append(np.mean(train_y))
    seasonal_avg_pred = np.array(seasonal_avg_pred)
    seasonal_avg_mae = np.mean(np.abs(test_y - seasonal_avg_pred))

    # Model 5: Linear Trend
    x_train = np.arange(len(train_y))
    x_test = np.arange(len(train_y), len(train_y) + 4)
    trend_coef = np.polyfit(x_train, train_y, 1)
    trend_pred = trend_coef[0] * x_test + trend_coef[1]
    trend_mae = np.mean(np.abs(test_y - trend_pred))

    # NÉ™ticÉ™lÉ™r
    models = {
        "Naive": {
            "ad": "Naive Forecast",
            "tÉ™svir": "Son dÉ™yÉ™r gÉ™lÉ™cÉ™k dÉ™yÉ™r kimi qÉ™bul edilir",
            "mae": round(naive_mae, 2),
            "rank": 0,
            "Ã¼stÃ¼nlÃ¼k": "Æn sadÉ™, hesablamasÄ± asan",
            "Ã§atÄ±ÅŸmazlÄ±q": "Trend vÉ™ mÃ¶vsÃ¼milik nÉ™zÉ™rÉ™ alÄ±nmÄ±r",
            "uyÄŸun_olduÄŸu_vÉ™ziyyÉ™t": "Ã‡ox sabit mÉ™lumatlar"
        },
        "Moving_Average": {
            "ad": "Moving Average (MA-4)",
            "tÉ™svir": "Son 4 rÃ¼bÃ¼n ortalamasÄ±",
            "mae": round(ma_mae, 2),
            "rank": 0,
            "Ã¼stÃ¼nlÃ¼k": "SÉ™s-kÃ¼yÃ¼ azaldÄ±r, sabitdir",
            "Ã§atÄ±ÅŸmazlÄ±q": "Trend vÉ™ mÃ¶vsÃ¼miliyÉ™ az hÉ™ssas",
            "uyÄŸun_olduÄŸu_vÉ™ziyyÉ™t": "SÉ™s-kÃ¼ylÃ¼ lakin trendsiz mÉ™lumatlar"
        },
        "Seasonal_Naive": {
            "ad": "Seasonal Naive",
            "tÉ™svir": "HÉ™r rÃ¼b Ã¼Ã§Ã¼n keÃ§miÅŸ ilin eyni rÃ¼bÃ¼nÃ¼n dÉ™yÉ™ri",
            "mae": round(seasonal_naive_mae, 2),
            "rank": 0,
            "Ã¼stÃ¼nlÃ¼k": "MÃ¶vsÃ¼miliyi tutur",
            "Ã§atÄ±ÅŸmazlÄ±q": "Trend nÉ™zÉ™rÉ™ alÄ±nmÄ±r",
            "uyÄŸun_olduÄŸu_vÉ™ziyyÉ™t": "GÃ¼clÃ¼ mÃ¶vsÃ¼milik, zÉ™if trend"
        },
        "Seasonal_Average": {
            "ad": "Seasonal Average",
            "tÉ™svir": "HÉ™r rÃ¼b Ã¼Ã§Ã¼n keÃ§miÅŸ bÃ¼tÃ¼n eyni rÃ¼blÉ™rin ortalamasÄ±",
            "mae": round(seasonal_avg_mae, 2),
            "rank": 0,
            "Ã¼stÃ¼nlÃ¼k": "MÃ¶vsÃ¼miliyi tutur, daha sabitdir",
            "Ã§atÄ±ÅŸmazlÄ±q": "Trend vÉ™ son dÉ™yiÅŸikliklÉ™rÉ™ az hÉ™ssas",
            "uyÄŸun_olduÄŸu_vÉ™ziyyÉ™t": "GÃ¼clÃ¼ mÃ¶vsÃ¼milik, zÉ™if trend"
        },
        "Linear_Trend": {
            "ad": "Linear Trend",
            "tÉ™svir": "XÉ™tti trendin davamÄ±",
            "mae": round(trend_mae, 2),
            "rank": 0,
            "Ã¼stÃ¼nlÃ¼k": "Trendi tutur",
            "Ã§atÄ±ÅŸmazlÄ±q": "MÃ¶vsÃ¼milik nÉ™zÉ™rÉ™ alÄ±nmÄ±r",
            "uyÄŸun_olduÄŸu_vÉ™ziyyÉ™t": "GÃ¼clÃ¼ xÉ™tti trend"
        }
    }

    # Ranking
    sorted_models = sorted(models.items(), key=lambda x: x[1]["mae"])
    for i, (name, _) in enumerate(sorted_models, 1):
        models[name]["rank"] = i

    best_model = sorted_models[0][0]

    return {
        "model_mÃ¼qayisÉ™si_nÉ™dir": {
            "tÉ™svir": "Model mÃ¼qayisÉ™si mÃ¼xtÉ™lif proqnoz metodlarÄ±nÄ±n keÃ§miÅŸ mÉ™lumatlar Ã¼zrÉ™ performansÄ±nÄ± Ã¶lÃ§Ã¼r vÉ™ É™n yaxÅŸÄ± metodu mÃ¼É™yyÉ™n edir.",
            "metrika": "MAE (Mean Absolute Error) - ortalama mÃ¼tlÉ™q xÉ™ta. KiÃ§ik MAE = Daha yaxÅŸÄ± model",
            "test_metodu": "Son 4 rÃ¼b test mÉ™lumatÄ± kimi ayrÄ±ldÄ±, qalan mÉ™lumatlarla model quruldu",
            "niyÉ™_vacibdir": "HÉ™r mÉ™lumat toplusu Ã¼Ã§Ã¼n É™n uyÄŸun metodu seÃ§mÉ™k proqnoz dÉ™qiqliyini artÄ±rÄ±r"
        },
        "modellÉ™r": models,
        "nÉ™ticÉ™": {
            "É™n_yaxÅŸÄ±_model": models[best_model]["ad"],
            "mae": models[best_model]["mae"],
            "izah": f"{models[best_model]['ad']} modeli É™n kiÃ§ik xÉ™taya malikdir vÉ™ bu mÉ™lumat toplusu Ã¼Ã§Ã¼n É™n uyÄŸundur",
            "tÃ¶vsiyÉ™": models[best_model]["uyÄŸun_olduÄŸu_vÉ™ziyyÉ™t"]
        },
        "praktik_tÃ¶vsiyÉ™": {
            "birinci_seÃ§im": models[best_model]["ad"],
            "ehtiyat_seÃ§im": models[sorted_models[1][0]]["ad"],
            "kombinÉ™_yanaÅŸma": "Æn yaxÅŸÄ± 2-3 metodun ortalama proqnozunu istifadÉ™ edÉ™rÉ™k riski azaltmaq olar",
            "mÉ™slÉ™hÉ™t": "Model performansÄ±nÄ± mÃ¼ntÉ™zÉ™m yoxlayÄ±n vÉ™ yeni mÉ™lumatlar É™lavÉ™ olunduqca yenidÉ™n qiymÉ™tlÉ™ndirin"
        }
    }
